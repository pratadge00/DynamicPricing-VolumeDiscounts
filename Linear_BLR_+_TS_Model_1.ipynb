{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# Phase‑1 · Data loading & feature preparation\n",
    "# ---------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load the dataset ---\n",
    "file_path = r'D:\\IITR DS Final Year Thesis\\Dataset Superstore\\archive\\generated_single_product_dataset_with_seasonal_variation.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- 2. Parse dates & sort chronologically ---\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# --- 3. Verify / recreate seasonal indices ---\n",
    "# If the CSV already contains these columns, this will simply overwrite with correct values\n",
    "df['day_of_year'] = df['date'].dt.dayofyear\n",
    "df['day_of_week'] = df['date'].dt.weekday          # Monday=0 … Sunday=6  (matches your earlier screenshots)\n",
    "\n",
    "# --- 4. Annual seasonality terms (period = 365 days) ---\n",
    "df['sin_annual'] = np.sin(2 * np.pi * df['day_of_year'] / 365.0)\n",
    "df['cos_annual'] = np.cos(2 * np.pi * df['day_of_year'] / 365.0)\n",
    "\n",
    "# --- 5. Weekly dummy variables (baseline = day 0) ---\n",
    "weekly_dummies = pd.get_dummies(df['day_of_week'], prefix='dow', drop_first=True)\n",
    "df = pd.concat([df, weekly_dummies], axis=1)\n",
    "\n",
    "# --- 6. Optional quick check ---\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# Keep a list of feature columns (intercept will be added later in the modelling block)\n",
    "weekly_cols = [c for c in df.columns if c.startswith('dow_')]   # dow_1 … dow_6\n",
    "static_feature_cols = weekly_cols + ['sin_annual', 'cos_annual']  # for reuse in later blocks\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Block 1 · Prior specification & model initialisation\n",
    "# ---------------------------------------------------------------\n",
    "#\n",
    "# Goal:\n",
    "#   • Define the complete feature set that drives demand\n",
    "#   • Encode informative but weakly‑restrictive priors\n",
    "#   • Instantiate the posterior mean / covariance that will be\n",
    "#     updated transaction‑by‑transaction in Block 3\n",
    "#   • Record a few handy constants for later use\n",
    "#\n",
    "# Assumes that Block 0 has already created:\n",
    "#   - df                       ← the cleaned DataFrame\n",
    "#   - static_feature_cols      ← weekly dummies + ['sin_annual', 'cos_annual']\n",
    "#     (intercept and price will be appended below)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 1.  Assemble feature list  (order matters – keep it consistent)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# Rename price column once for convenience\n",
    "if 'price' not in df.columns:\n",
    "    df['price'] = df['price_paid']          #   ← demand model uses this name\n",
    "\n",
    "feature_cols   = ['intercept'] + static_feature_cols + ['price']\n",
    "idx_price      = len(feature_cols) - 1      # index of the price coefficient\n",
    "n_features     = len(feature_cols)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 2.  Set prior means  (μ₀)  — weakly informative\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "prior_mean = np.zeros(n_features)\n",
    "\n",
    "# Intercept: start around the median quantity sold\n",
    "prior_mean[0] = df['quantity'].median()     # e.g. ~25–30 units\n",
    "\n",
    "# Weekly / annual terms default to 0  (no seasonal bias initially)\n",
    "\n",
    "# Price coefficient: strongly expected to be negative\n",
    "prior_mean[idx_price] = -1.0                # units: Δquantity / Δprice\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 3.  Set prior covariance  (Σ₀ = diag(σ²))\n",
    "#     larger σ² ⇒ weaker prior confidence\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "prior_sd = np.ones(n_features) * 10.0       # default ±10 units on coeffs\n",
    "prior_sd[idx_price] = 1.0                   # tighter on price slope\n",
    "\n",
    "prior_cov = np.diag(prior_sd ** 2)          # (n_features × n_features)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 4.  Observation noise variance  (σ²_ε)\n",
    "#     Use sample std of quantity as a rough starting point\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "sigma = df['quantity'].std()                # ≈ 12–15 for your synthetic data\n",
    "sigma2 = sigma ** 2\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 5.  Initialise posterior as the prior\n",
    "#     (will be updated online in Block 3)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "post_mean = prior_mean.copy()\n",
    "post_cov  = prior_cov.copy()\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 6.  Convenience constants\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "price_bounds   = (df['price'].min(), df['price'].max())   # for clamping TS prices\n",
    "cost_per_unit  = df['cost'].mean()                        # will be used for profit calc\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 7.  Quick sanity printout\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "print(\"➤ Feature columns:\", feature_cols)\n",
    "print(\"➤ Prior mean:\", prior_mean.round(2))\n",
    "print(\"➤ Prior SD  :\", prior_sd.round(2))\n",
    "print(f\"➤ Obs‑noise σ² ≈ {sigma2:.2f}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Block 2 · Utility helpers\n",
    "# ---------------------------------------------------------------\n",
    "#\n",
    "# Pure‑Python functions that keep the main loop tidy.\n",
    "# They assume these variables already exist in the workspace:\n",
    "#   • weekly_cols       – list like ['dow_1', …, 'dow_6']\n",
    "#   • price_bounds      – tuple (p_min, p_max)  from Block 1\n",
    "#   • cost_per_unit     – scalar, average cost  (can be overridden)\n",
    "#   • sigma2            – observation‑noise variance\n",
    "#\n",
    "# You can import this module in a larger project, or simply\n",
    "# execute the cell once before running Block 3.\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 1.  Feature‑vector builders\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def build_static_vector(row, weekly_cols=weekly_cols):\n",
    "    \"\"\"\n",
    "    Returns the *static* part of the feature vector for a single\n",
    "    transaction (no price term):\n",
    "        [1, dow_1 … dow_6, sin_annual, cos_annual]\n",
    "    \"\"\"\n",
    "    vec = [1.0]                                         # intercept\n",
    "    vec.extend([row.get(col, 0.0) for col in weekly_cols])\n",
    "    vec.append(row['sin_annual'])\n",
    "    vec.append(row['cos_annual'])\n",
    "    return np.array(vec, dtype=float)                   # shape (len(weekly_cols)+3,)\n",
    "\n",
    "def make_feature_vector(row, weekly_cols=weekly_cols):\n",
    "    \"\"\"\n",
    "    Complete feature vector including the *actual* price in the row.\n",
    "    \"\"\"\n",
    "    static_vec = build_static_vector(row, weekly_cols)\n",
    "    return np.concatenate([static_vec, [row['price']]]) # final len = n_features\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 2.  Price‑optimisation under a sampled θ (Thompson step)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def optimal_price_thompson(theta, static_vec,\n",
    "                           price_bounds=price_bounds,\n",
    "                           cost=cost_per_unit):\n",
    "    \"\"\"\n",
    "    Given:\n",
    "        θ         – sampled coefficient vector  (len = n_features)\n",
    "        static_vec– context WITHOUT price term  (same length as θ‑1)\n",
    "    returns the profit‑maximising price P* within price_bounds.\n",
    "\n",
    "    Demand model:  Q = A + B·P\n",
    "       A = θ_static · static_vec\n",
    "       B = θ_price\n",
    "    Profit:        π(P) = (P - cost) * Q\n",
    "\n",
    "    Closed‑form maximiser (if B < 0):\n",
    "        P* = (cost·B - A) / (2·B)\n",
    "\n",
    "    Fallbacks:\n",
    "        • B == 0 → pick lower bound (explore low price)\n",
    "        • B  > 0 → pick upper bound (monotonic violation → safe edge)\n",
    "    \"\"\"\n",
    "    A = float(np.dot(theta[:-1], static_vec))\n",
    "    B = float(theta[-1])\n",
    "\n",
    "    if B < 0:                                           # expected case\n",
    "        p_star = (cost * B - A) / (2.0 * B)\n",
    "        # Numeric guard\n",
    "        if not np.isfinite(p_star):\n",
    "            p_star = 0.5 * (price_bounds[0] + price_bounds[1])\n",
    "    elif B == 0:\n",
    "        p_star = price_bounds[0]\n",
    "    else:                                               # B > 0 (unlikely after learning)\n",
    "        p_star = price_bounds[1]\n",
    "\n",
    "    # Clamp to observed range\n",
    "    p_star = max(price_bounds[0], min(price_bounds[1], p_star))\n",
    "    return p_star\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 3.  One‑step Bayesian update (Kalman style)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def kalman_update(mean, cov, x_vec, y_obs, sigma2=sigma2):\n",
    "    \"\"\"\n",
    "    Perform the conjugate Bayesian update for linear‑Gaussian\n",
    "    regression on a single (x, y) observation.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "      mean  : current posterior mean      (n,)\n",
    "      cov   : current posterior covariance(n,n)\n",
    "      x_vec : feature vector              (n,)\n",
    "      y_obs : scalar target\n",
    "      sigma2: observation noise variance\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "      new_mean, new_cov   – updated posterior parameters\n",
    "    \"\"\"\n",
    "    x = x_vec.reshape(-1, 1)                            # (n,1)\n",
    "    S = sigma2 + float(x.T @ cov @ x)                   # predictive var\n",
    "    K = (cov @ x) / S                                   # Kalman gain  (n,1)\n",
    "    residual = y_obs - float(mean @ x)                  # innovation\n",
    "    new_mean = mean + (K.flatten() * residual)          # (n,)\n",
    "    new_cov  = cov - K @ (x.T @ cov)                    # rank‑1 update\n",
    "    # Enforce symmetry\n",
    "    new_cov  = 0.5 * (new_cov + new_cov.T)\n",
    "    return new_mean, new_cov\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 4.  Tiny helper for clamping generic scalars\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def clamp(val, lo, hi):\n",
    "    return max(lo, min(hi, val))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Block 3 · Online BLR + Thompson‑Sampling loop\n",
    "# ------------------------------------------------------------------\n",
    "# Prerequisites  (make sure Blocks 0‑2 ran first):\n",
    "#   • df                 – time‑sorted DataFrame\n",
    "#   • feature_cols       – full feature list (Block 1)\n",
    "#   • post_mean, post_cov, sigma2, idx_price\n",
    "#   • build_static_vector(), optimal_price_thompson(), kalman_update()\n",
    "#\n",
    "# What this block does\n",
    "#   1. Pre‑computes static context vectors (fast lookup)\n",
    "#   2. Iterates through all 10 000 transactions in sequence\n",
    "#   3. For each tx:\n",
    "#        • one‑step‑ahead demand prediction\n",
    "#        • Thompson draw  → recommended price\n",
    "#        • log actuals & profit\n",
    "#        • Bayesian (Kalman) update of posterior\n",
    "#   4. Stores *every* series you’ll need for diagnostics /\n",
    "#      visualisation in the next blocks, and pickles them to disk.\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 1.  Pre‑compute static context matrix  (no price term)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "static_matrix = np.stack(df.apply(build_static_vector, axis=1).values)  # shape (N, len(static)+1)\n",
    "prices        = df['price'].values\n",
    "quantities    = df['quantity'].values\n",
    "N             = len(df)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 2.  Prepare logging containers\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "rec_prices          = np.empty(N)                # Thompson‑recommended\n",
    "act_prices          = prices                     # alias; kept for symmetry\n",
    "act_qty             = quantities\n",
    "pred_qty            = np.empty(N)                # one‑step‑ahead predictions\n",
    "post_means_price    = np.empty(N)                # trace of β_price mean\n",
    "profits             = np.empty(N)\n",
    "cum_profit          = np.empty(N)\n",
    "residuals           = np.empty(N)\n",
    "theta_trace         = np.empty((N, len(feature_cols)))  # posterior mean each step\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 3.  Online loop\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "pm = post_mean.copy()     # start from prior (Block 1)\n",
    "pc = post_cov.copy()\n",
    "\n",
    "for i in tqdm(range(N), desc=\"Online BLR updating\", ncols=80):\n",
    "\n",
    "    # ------ context & actual outcome ----------------------------------\n",
    "    static_vec = static_matrix[i]                # (len(static)+1,)\n",
    "    price_i    = prices[i]\n",
    "    qty_i      = quantities[i]\n",
    "\n",
    "    # ------ one‑step‑ahead prediction (using current posterior mean) ---\n",
    "    x_i = np.concatenate([static_vec, [price_i]])\n",
    "    y_hat = float(pm @ x_i)\n",
    "    pred_qty[i] = y_hat\n",
    "    residuals[i] = qty_i - y_hat\n",
    "\n",
    "    # ------ Thompson‑sampling price recommendation --------------------\n",
    "    theta_sample = np.random.multivariate_normal(pm, pc)\n",
    "    p_star = optimal_price_thompson(theta_sample, static_vec)\n",
    "    rec_prices[i] = p_star\n",
    "\n",
    "    # ------ Profit realised with the *actual* historical price --------\n",
    "    profit_i = (price_i - cost_per_unit) * qty_i\n",
    "    profits[i] = profit_i\n",
    "    cum_profit[i] = profit_i if i == 0 else cum_profit[i-1] + profit_i\n",
    "\n",
    "    # ------ Log posterior mean trace ----------------------------------\n",
    "    post_means_price[i] = pm[idx_price]\n",
    "    theta_trace[i] = pm\n",
    "\n",
    "    # ------ Bayesian (Kalman) update with observed (x_i, qty_i) -------\n",
    "    pm, pc = kalman_update(pm, pc, x_i, qty_i)   # returns updated mean & cov\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 4.  Final posterior snapshot\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "post_mean_final = pm.copy()\n",
    "post_cov_final  = pc.copy()\n",
    "\n",
    "print(f\"\\nTraining complete.  Final β_price mean = {post_mean_final[idx_price]:.4f}\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 5.  Persist logs so you can reload later without rerun\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "logs_path = os.path.join(results_dir, \"phase1_logs.pkl\")\n",
    "\n",
    "logs = {\n",
    "    \"feature_cols\"      : feature_cols,\n",
    "    \"recommended_price\" : rec_prices,\n",
    "    \"actual_price\"      : act_prices,\n",
    "    \"actual_quantity\"   : act_qty,\n",
    "    \"predicted_quantity\": pred_qty,\n",
    "    \"price_coef_mean\"   : post_means_price,\n",
    "    \"profit\"            : profits,\n",
    "    \"cum_profit\"        : cum_profit,\n",
    "    \"residuals\"         : residuals,\n",
    "    \"theta_trace\"       : theta_trace,\n",
    "    \"post_mean_final\"   : post_mean_final,\n",
    "    \"post_cov_final\"    : post_cov_final,\n",
    "    \"sigma2\"            : sigma2,\n",
    "    \"price_bounds\"      : price_bounds,\n",
    "    \"cost_per_unit\"     : cost_per_unit,\n",
    "}\n",
    "\n",
    "with open(logs_path, \"wb\") as f:\n",
    "    pickle.dump(logs, f)\n",
    "\n",
    "print(f\"➤ Logs saved to {logs_path}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Block 4 · Persist / reload intermediate results\n",
    "# ------------------------------------------------------------------\n",
    "# Purpose\n",
    "#   • Store the logged arrays from Block 3 in *human‑friendly*\n",
    "#     formats (CSV, NPZ, JSON) so you can reload or inspect them\n",
    "#     without rerunning the full online loop.\n",
    "#   • Provide a tiny helper to load everything back in one call.\n",
    "#\n",
    "# Usage\n",
    "#   • Run this cell *after* Block 3 (the ‘logs’ dict must exist),\n",
    "#     OR let it auto‑load the default pickle if you started a\n",
    "#     fresh session and haven’t recreated logs in memory yet.\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "import os, pickle, json, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 1.  Locate / load the logs dict\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "try:\n",
    "    logs  # is it already in RAM?\n",
    "except NameError:\n",
    "    default_pkl = os.path.join(\"results\", \"phase1_logs.pkl\")\n",
    "    if not os.path.isfile(default_pkl):\n",
    "        raise FileNotFoundError(\n",
    "            \"No in‑memory ‘logs’ and default pickle not found. \"\n",
    "            \"Run Block 3 first or point to a specific pickle.\"\n",
    "        )\n",
    "    with open(default_pkl, \"rb\") as f:\n",
    "        logs = pickle.load(f)\n",
    "    print(f\"✓ Loaded logs from {default_pkl}\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 2.  Create a unique results sub‑folder\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "timestamp   = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "base_dir    = os.path.join(\"results\", f\"phase1_{timestamp}\")\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 3.  Transaction‑level CSV  (easiest to eyeball in Excel/R)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "df_logs = pd.DataFrame({\n",
    "    \"recommended_price\" : logs[\"recommended_price\"],\n",
    "    \"actual_price\"      : logs[\"actual_price\"],\n",
    "    \"actual_quantity\"   : logs[\"actual_quantity\"],\n",
    "    \"predicted_quantity\": logs[\"predicted_quantity\"],\n",
    "    \"profit\"            : logs[\"profit\"],\n",
    "    \"cum_profit\"        : logs[\"cum_profit\"],\n",
    "    \"beta_price_mean\"   : logs[\"price_coef_mean\"],\n",
    "})\n",
    "csv_path = os.path.join(base_dir, \"transaction_logs.csv\")\n",
    "df_logs.to_csv(csv_path, index_label=\"transaction_index\")\n",
    "print(f\"✓ CSV saved → {csv_path}\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 4.  θ‑trace (posterior mean of *all* coeffs at every step)\n",
    "#     → compressed NPZ to keep file size modest\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "theta_path = os.path.join(base_dir, \"theta_trace.npz\")\n",
    "np.savez_compressed(theta_path, theta=logs[\"theta_trace\"])\n",
    "print(f\"✓ θ‑trace saved → {theta_path}\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 5.  Final posterior arrays for warm‑starts or later analysis\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "np.save(os.path.join(base_dir, \"beta_mean_final.npy\"), logs[\"post_mean_final\"])\n",
    "np.save(os.path.join(base_dir, \"beta_cov_final.npy\"),  logs[\"post_cov_final\"])\n",
    "print(\"✓ Final posterior mean / cov saved (.npy)\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 6.  Lightweight JSON meta‑info\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "meta = {\n",
    "    \"timestamp\"       : timestamp,\n",
    "    \"feature_cols\"    : logs[\"feature_cols\"],\n",
    "    \"sigma2\"          : float(logs[\"sigma2\"]),\n",
    "    \"price_bounds\"    : [float(x) for x in logs[\"price_bounds\"]],\n",
    "    \"cost_per_unit\"   : float(logs[\"cost_per_unit\"]),\n",
    "    \"n_transactions\"  : int(len(logs[\"actual_price\"])),\n",
    "}\n",
    "meta_path = os.path.join(base_dir, \"meta.json\")\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "print(f\"✓ Meta‑info saved → {meta_path}\")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 7.  Handy loader for future notebooks / scripts\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "def load_phase1_results(folder):\n",
    "    \"\"\"\n",
    "    Reloads everything produced by this block.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "      df_logs       – pandas DataFrame (transaction‑level log)\n",
    "      theta_trace   – np.ndarray (N, n_features)\n",
    "      beta_mean_fin – np.ndarray (n_features,)\n",
    "      beta_cov_fin  – np.ndarray (n_features, n_features)\n",
    "      meta          – dict\n",
    "    \"\"\"\n",
    "    df_logs = pd.read_csv(os.path.join(folder, \"transaction_logs.csv\"),\n",
    "                          index_col=\"transaction_index\")\n",
    "    theta   = np.load(os.path.join(folder, \"theta_trace.npz\"))[\"theta\"]\n",
    "    beta_m  = np.load(os.path.join(folder, \"beta_mean_final.npy\"))\n",
    "    beta_c  = np.load(os.path.join(folder, \"beta_cov_final.npy\"))\n",
    "    with open(os.path.join(folder, \"meta.json\"), \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    return df_logs, theta, beta_m, beta_c, meta\n",
    "\n",
    "print(\"\\nHelper ready → load_phase1_results(<folder>)\")\n",
    "print(\"All artefacts safely stored.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Block 5 · Visualisation suite\n",
    "# ------------------------------------------------------------------\n",
    "# Six ready‑to‑run plots:\n",
    "#   5‑a  Demand curve vs. observed data   (★ most important)\n",
    "#   5‑b  Predicted vs actual demand over time\n",
    "#   5‑c  Cumulative profit over time\n",
    "#   5‑d  Price trajectory  (actual vs TS‑recommended)\n",
    "#   5‑e  Posterior mean of β_price over time\n",
    "#   5‑f  Histogram of one‑step‑ahead residuals\n",
    "#\n",
    "# Assumptions\n",
    "#   • Either the logs dict is still in RAM from Block 3/4 **or**\n",
    "#     you point results_folder at one of the saved folders\n",
    "#     created by Block 4.  All plots save a PNG alongside display.\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "import os, pickle, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 0.  Load results (if not already in memory)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "results_folder = None   # ⇠ set to e.g. \"results/phase1_20250505_211530\"\n",
    "                        #    or leave None to use in‑RAM logs\n",
    "\n",
    "if results_folder is None:\n",
    "    try:\n",
    "        logs\n",
    "    except NameError:\n",
    "        raise RuntimeError(\"logs dict not found in memory and \"\n",
    "                           \"results_folder is None.  \"\n",
    "                           \"Either run Blocks 3‑4 or set results_folder.\")\n",
    "    meta = None  # not needed when logs already in memory\n",
    "    df_logs = pd.DataFrame({\n",
    "        \"recommended_price\" : logs[\"recommended_price\"],\n",
    "        \"actual_price\"      : logs[\"actual_price\"],\n",
    "        \"actual_quantity\"   : logs[\"actual_quantity\"],\n",
    "        \"predicted_quantity\": logs[\"predicted_quantity\"],\n",
    "        \"profit\"            : logs[\"profit\"],\n",
    "        \"cum_profit\"        : logs[\"cum_profit\"],\n",
    "        \"beta_price_mean\"   : logs[\"price_coef_mean\"],\n",
    "    })\n",
    "    theta_trace        = logs[\"theta_trace\"]\n",
    "    post_mean_final    = logs[\"post_mean_final\"]\n",
    "    price_bounds       = logs[\"price_bounds\"]\n",
    "else:\n",
    "    # Use helper from Block 4\n",
    "    df_logs, theta_trace, post_mean_final, _, meta = load_phase1_results(results_folder)\n",
    "    price_bounds = meta[\"price_bounds\"]\n",
    "\n",
    "# Ensure an output dir for plots\n",
    "plots_dir = os.path.join(results_folder if results_folder else \"results\", \"plots\")\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "# Short aliases\n",
    "N = len(df_logs)\n",
    "price_min, price_max = price_bounds\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5‑a  Estimated demand curve (baseline context) vs observed data\n",
    "# ---------------------------------------------------------------\n",
    "# Baseline context = day_of_week 0 (all dummies 0), sin=0, cos=1\n",
    "n_static = len(post_mean_final) - 1\n",
    "baseline_static = np.zeros(n_static)\n",
    "baseline_static[0] = 1.0                     # intercept is first static entry\n",
    "\n",
    "price_grid = np.linspace(price_min, price_max, 250)\n",
    "q_pred_curve = post_mean_final[:-1] @ baseline_static + post_mean_final[-1] * price_grid\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "# scatter – sample for clarity if dataset is huge\n",
    "sample_idx = np.random.choice(N, size=min(3000, N), replace=False)\n",
    "plt.scatter(df_logs[\"actual_price\"].iloc[sample_idx],\n",
    "            df_logs[\"actual_quantity\"].iloc[sample_idx],\n",
    "            s=14, alpha=0.25, label=\"Observed transactions\")\n",
    "\n",
    "plt.plot(price_grid, q_pred_curve, color=\"darkorange\", linewidth=2.5,\n",
    "         label=\"Final estimated demand curve\\n(baseline context)\")\n",
    "\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Quantity demanded\")\n",
    "plt.title(\"Estimated Demand Curve vs Observed Data\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, \"demand_curve.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5‑b  Predicted vs actual demand over time\n",
    "# ---------------------------------------------------------------\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df_logs[\"actual_quantity\"].values, label=\"Actual qty\", linewidth=1.1)\n",
    "plt.plot(df_logs[\"predicted_quantity\"].values, label=\"Predicted qty (1‑step ahead)\",\n",
    "         linestyle=\"--\", linewidth=1.1)\n",
    "plt.xlabel(\"Transaction index (chronological)\")\n",
    "plt.ylabel(\"Quantity\")\n",
    "plt.title(\"Predicted vs Actual Demand Over Time\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, \"pred_vs_actual.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5‑c  Cumulative profit over time\n",
    "# ---------------------------------------------------------------\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(df_logs[\"cum_profit\"].values, color=\"seagreen\")\n",
    "plt.xlabel(\"Transaction index\")\n",
    "plt.ylabel(\"Cumulative profit\")\n",
    "plt.title(\"Cumulative Profit Curve\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, \"cumulative_profit.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5‑d  Price trajectory: actual vs TS‑recommended\n",
    "# ---------------------------------------------------------------\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df_logs[\"actual_price\"].values, label=\"Actual price\", alpha=0.7, linewidth=1)\n",
    "plt.plot(df_logs[\"recommended_price\"].values, label=\"TS‑recommended price\", linewidth=1)\n",
    "plt.xlabel(\"Transaction index\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(\"Price Trajectory – Actual vs Thompson‑Sampling Recommendation\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, \"price_trajectory.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5‑e  Posterior mean of β_price over time\n",
    "# ---------------------------------------------------------------\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(df_logs[\"beta_price_mean\"].values, color=\"firebrick\")\n",
    "plt.axhline(0, color=\"k\", linewidth=0.8)\n",
    "plt.xlabel(\"Transaction index\")\n",
    "plt.ylabel(\"Posterior mean of β_price\")\n",
    "plt.title(\"Convergence of Price‑Slope Coefficient\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, \"beta_price_trace.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5‑f  Histogram of one‑step residuals\n",
    "# ---------------------------------------------------------------\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(df_logs[\"actual_quantity\"] - df_logs[\"predicted_quantity\"],\n",
    "         bins=60, alpha=0.8, edgecolor=\"k\")\n",
    "plt.xlabel(\"Residual (actual − predicted)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of 1‑Step‑Ahead Prediction Residuals\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, \"residual_hist.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ All plots saved to {plots_dir}\")\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 5‑g  Thompson‑Sampling realisation & optimal‑price illustration\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "\n",
    "def plot_ts_realization(idx, K=40, price_points=200, save=True):\n",
    "    \"\"\"\n",
    "    Recreates a Figure‑4 style illustration for transaction idx.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    idx           : int   – index of the transaction (chronological order)\n",
    "    K             : int   – how many posterior samples to visualise as 'uncertainty'\n",
    "    price_points  : int   – resolution of the price grid\n",
    "    save          : bool  – if True, PNG saved to plots_dir\n",
    "    \n",
    "    Produces\n",
    "    --------\n",
    "      A 3‑panel Matplotlib figure:\n",
    "         (1) Posterior mean demand + K grey samples   → 'Uncertainty'\n",
    "         (2) One Thompson sample highlighted in green\n",
    "         (3) Revenue curve for that sample with p*τ   → dotted red vs green\n",
    "    \"\"\"\n",
    "    assert 0 <= idx < N, \"idx out of range\"\n",
    "    \n",
    "    # ---------------- context & posterior ----------------------\n",
    "    row          = df.iloc[idx]\n",
    "    static_vec   = build_static_vector(row)\n",
    "    cost         = cost_per_unit                           # mean cost from earlier\n",
    "    \n",
    "    # Use *final* posterior for uncertainty envelope (simpler)\n",
    "    beta_mean    = post_mean_final\n",
    "    beta_cov     = post_cov_final\n",
    "    \n",
    "    # Price grid for curves\n",
    "    p_grid = np.linspace(price_min, price_max, price_points)\n",
    "    \n",
    "    # -- Posterior mean demand curve (baseline prediction) -----\n",
    "    A_mean = beta_mean[:-1] @ static_vec\n",
    "    B_mean = beta_mean[-1]\n",
    "    q_mean_curve = A_mean + B_mean * p_grid\n",
    "    \n",
    "    # -- K posterior samples to illustrate uncertainty ---------\n",
    "    theta_samples = np.random.multivariate_normal(beta_mean, beta_cov, size=K)\n",
    "    q_samples = np.outer(theta_samples[:, :-1] @ static_vec, np.ones_like(p_grid)) \\\n",
    "                + (theta_samples[:, -1][:, None] * p_grid)\n",
    "    \n",
    "    # -- Thompson draw for idx (these days we simply draw anew)--\n",
    "    theta_ts = np.random.multivariate_normal(beta_mean, beta_cov)\n",
    "    A_ts, B_ts = theta_ts[:-1] @ static_vec, theta_ts[-1]\n",
    "    q_ts_curve = A_ts + B_ts * p_grid\n",
    "    if B_ts < 0:\n",
    "        p_opt_ts = (cost * B_ts - A_ts) / (2 * B_ts)\n",
    "        p_opt_ts = max(price_min, min(price_max, p_opt_ts))\n",
    "    else:\n",
    "        p_opt_ts = price_max if B_ts > 0 else price_min\n",
    "    \n",
    "    # Historical & recommended price from our logs\n",
    "    p_actual = df_logs[\"actual_price\"].iloc[idx]\n",
    "    p_rec    = df_logs[\"recommended_price\"].iloc[idx]\n",
    "    \n",
    "    # ---------------- revenue curve for the TS sample ----------\n",
    "    revenue_ts = (p_grid - cost) * q_ts_curve\n",
    "    \n",
    "    # =====================  PLOT  ==============================\n",
    "    fig = plt.figure(figsize=(11,3.4))\n",
    "    gs  = GridSpec(1, 3, wspace=0.28)\n",
    "    \n",
    "    # Panel 1 – Uncertainty band\n",
    "    ax1 = fig.add_subplot(gs[0,0])\n",
    "    for k in range(K):\n",
    "        ax1.plot(p_grid, q_samples[k], color=\"lightgrey\", linewidth=0.8)\n",
    "    ax1.plot(p_grid, q_mean_curve, color=\"black\", linewidth=2,\n",
    "             label=\"Posterior mean\")\n",
    "    ax1.set_title(\"Posterior demand & uncertainty\")\n",
    "    ax1.set_xlabel(\"Price  p\");  ax1.set_ylabel(\"Quantity  v\")\n",
    "    ax1.legend(frameon=False)\n",
    "    \n",
    "    # Panel 2 – Thompson sample realisation\n",
    "    ax2 = fig.add_subplot(gs[0,1])\n",
    "    for k in range(K):\n",
    "        ax2.plot(p_grid, q_samples[k], color=\"lightgrey\", linewidth=0.8)\n",
    "    ax2.plot(p_grid, q_ts_curve, color=\"forestgreen\", linewidth=2,\n",
    "             label=\"TS sample\")\n",
    "    ax2.set_title(\"Thompson‑sampled demand curve\")\n",
    "    ax2.set_xlabel(\"Price  p\");  ax2.set_yticks([])\n",
    "    ax2.legend(frameon=False)\n",
    "    \n",
    "    # Panel 3 – Objective (revenue) & p*τ marker\n",
    "    ax3 = fig.add_subplot(gs[0,2])\n",
    "    ax3.plot(p_grid, revenue_ts, color=\"crimson\", linestyle=\"--\",\n",
    "             label=\"Revenue curve  (objective)\")\n",
    "    ax3.axvline(p_opt_ts, color=\"black\", linewidth=2,\n",
    "                label=f\"p*τ  (TS optimum ≈ {p_opt_ts:,.1f})\")\n",
    "    ax3.scatter([p_actual], [0], color=\"steelblue\", zorder=4,\n",
    "                label=f\"Historical price = {p_actual:,.1f}\")\n",
    "    ax3.scatter([p_rec], [0], color=\"purple\", zorder=4,\n",
    "                label=f\"Our rec. price = {p_rec:,.1f}\")\n",
    "    ax3.set_ylabel(\"Revenue  v·(p−c)\");  ax3.set_xlabel(\"Price  p\")\n",
    "    ax3.set_title(\"Objective & optimal price\")\n",
    "    ax3.legend(frameon=False, loc=\"upper right\")\n",
    "    \n",
    "    fig.suptitle(f\"TS Figure – transaction τ = {idx}\", y=1.03, fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        fname = os.path.join(plots_dir, f\"ts_figure_tau_{idx}.png\")\n",
    "        fig.savefig(fname, dpi=150, bbox_inches=\"tight\")\n",
    "        print(f\"✓ Figure saved → {fname}\")\n",
    "    plt.show()\n",
    "\n",
    "# --------------------  Example usage  ---------------------------\n",
    "# plot_ts_realization(5000)   # choose any τ you’re curious about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a081a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ════════════════════════════════════════════════════════════════\n",
    "#  SNAPSHOT CURRENT MODEL‑1 RESULTS ⇒  results_model_1\n",
    "#  ▸ Run this RIGHT AFTER Model‑1’s training/persistence blocks.\n",
    "#  ▸ No re‑loading needed – we just point to the in‑memory objects.\n",
    "#  ▸ Automatic fallback: if key objects are missing (e.g. after\n",
    "#    a kernel restart) we reload the most recent phase1_* folder.\n",
    "# ════════════════════════════════════════════════════════════════\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 1.  Detect whether key objects are already in RAM\n",
    "#     (they are created by Model‑1’s Block 3 & Block 4)\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "have_in_memory = all(name in globals() for name in [\n",
    "    \"logs\",            # dict with raw arrays\n",
    "    \"df_logs\",         # pretty transaction DataFrame\n",
    "    \"theta_trace\",     # posterior mean path\n",
    "    \"post_mean_final\", # final μ\n",
    "    \"post_cov_final\",  # final Σ\n",
    "])\n",
    "\n",
    "if have_in_memory:\n",
    "    print(\"✓ Found Model‑1 artefacts in memory – no disk reload needed.\")\n",
    "    model1_folder = globals().get(\"base_dir\", \"\") or \"‑in‑memory‑run‑\"\n",
    "    df_logs1      = df_logs\n",
    "    theta1        = theta_trace\n",
    "    mu1           = post_mean_final\n",
    "    Sigma1        = post_cov_final\n",
    "    meta1         = {\n",
    "        \"feature_cols\" : logs[\"feature_cols\"],\n",
    "        \"price_bounds\" : logs[\"price_bounds\"],\n",
    "        \"sigma2\"       : logs[\"sigma2\"],\n",
    "        \"cost_per_unit\": logs[\"cost_per_unit\"],\n",
    "        \"folder\"       : model1_folder\n",
    "    }\n",
    "\n",
    "else:\n",
    "    # ────────────────────────────────────────────────────────────\n",
    "    # 2.  Fallback – reload latest phase1_* folder from ./results\n",
    "    # ────────────────────────────────────────────────────────────\n",
    "    try:\n",
    "        load_phase1_results\n",
    "    except NameError as err:\n",
    "        raise NameError(\"Model‑1 objects not in RAM and helper \"\n",
    "                        \"`load_phase1_results()` is missing. \"\n",
    "                        \"Run Model‑1’s persistence block first.\") from err\n",
    "\n",
    "    phase_dirs = sorted(\n",
    "        glob(os.path.join(\"results\", \"phase1_*\")),\n",
    "        key=os.path.getmtime\n",
    "    )\n",
    "    if not phase_dirs:\n",
    "        raise FileNotFoundError(\"No phase1_* folders found in ./results/. \"\n",
    "                                \"Run Model‑1 first.\")\n",
    "    model1_folder = phase_dirs[-1]            # newest folder\n",
    "    print(f\"ℹ Objects not in RAM  – reloading from  {model1_folder}\")\n",
    "    df_logs1, theta1, mu1, Sigma1, meta1 = load_phase1_results(model1_folder)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "# 3.  Bundle everything into one convenient dict\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "results_model_1 = {\n",
    "    \"folder\"     : model1_folder,\n",
    "    \"df_logs\"    : df_logs1,      # per‑transaction DataFrame\n",
    "    \"theta_trace\": theta1,        # (N, d) array\n",
    "    \"mu_final\"   : mu1,           # final posterior mean\n",
    "    \"Sigma_final\": Sigma1,        # final posterior covariance\n",
    "    \"meta\"       : meta1          # miscellaneous meta‑info\n",
    "}\n",
    "\n",
    "print(\"\\nresults_model_1 is now ready with keys:\")\n",
    "pprint.pp(results_model_1.keys())\n",
    "print(f\"\\n↳ Total profit recorded by Model‑1 = \"\n",
    "      f\"{results_model_1['df_logs']['profit'].sum():,.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
